---
created: 2025-12-31
tags:
  - AI
  - PromptEngineering
  - Philosophy
aliases:
  - AI対話能力進化マップ
  - Prompt_SkillMap_v6
  - プロンプトエンジニアリング完全ガイド
  - 魔法のプロンプト集
description: "「プロンプトを学べばAIを制御できる」という幻想を打ち砕き、真のエンジニアリングと共進化へ誘うためのトロイの木馬的スキルマップ。"
---

## 0. 前提能力：課題設定力 (The Engine)
すべてのレベルの基盤となるのが、**「何を解決すべきか」を定義する課題設定能力（Problem Setting Ability）」**である。
AIが進化し、CoT（思考の連鎖）すら自動化される中で、人間には以下の能力がより一層求められる。

*   **状況認識 (Situational Awareness)**: 文脈、背景、ターゲットの心情を深く読み取る力。
*   **前提条件の言語化 (Clarify Preconditions)**: AIに渡すべき制約（予算、時間、NGワード）を明確にする力。
*   **実践例**:
    *   ❌「ウェビナーの良い時間を教えて」
    *   ✅「ターゲットは24-45歳の残業を嫌う層。1時間のウェビナーを開催するなら、12:00-13:00と19:00以降のどちらが参加率が高いか推論せよ」

この能力がないままツールだけ覚えても、AIは「賢い馬鹿（正しく間違える機械）」にしかならない。

# プロンプトエンジニアリング・スキルマップ (Ver.6.0)
## 〜命令から対話、そして確信へ〜

プロンプトエンジニアリングは、単なる「命令文の書き方」ではありません。
それは人間とAIの関係性の進化プロセスそのものです。
本ドキュメントでは、AI活用の段階を「操作（Level 1）」から「真の対話（Level 6）」までの6段階で定義します。

---

## レベル1：基礎（操作理解と簡単な指示）
**目的**：AIに意図通りの答えを返させる最低限の書き方を知る
**関係性**：Master / Servant（命令と服従）

*   シンプルで直接的な命令文（例：「日本語に翻訳して」）
*   具体的な条件提示（例：「500文字以内で説明して」）
*   一問一答型の使い方
*   出力フォーマット指定（例：「箇条書きで答えて」）

**習熟の目安**：モデルの癖や反応傾向がだいたい読める。

---

## レベル2：中級（情報整理と条件組み合わせ）
**目的**：複数の条件や制約を組み合わせ、精度の高い出力を得る
**関係性**：Director / Actor（演出家と演者）

*   複数条件の同時指定（例：「ビジネスメール風で、短め、丁寧に」）
*   ロール設定（例：「あなたは経験豊富な法律アドバイザーです」）
*   出力構造のテンプレ化（見出し・ステップ構成など）
*   比較・要約・抽出の指示

**習熟の目安**：出力の再現性が安定し、意図とのズレが減る。（いわゆる「深津式」などの定型化アプローチ）

---

## レベル3：上級（高度な設計と段階的プロンプト）
**目的**：複雑な思考プロセスや複数フェーズをモデルに実行させる
**関係性**：Architect / Builder（設計者と施工者）

*   チェーン型（段階的思考）プロンプト
    *   → 「まず課題を分析し、その後解決案を3つ提案して」
*   Few-shot（例示学習）プロンプト
*   思考の枠組み指定（MECE・5W1H・因果関係など）
*   メタ認知的指示（例：「あなたの推論の弱点も指摘して」）

**習熟の目安**：個人の論理的思考力がプロンプトに反映され、複雑なタスクを構造化できる。

---

## パラダイムシフト：プロンプトからコンテキストへ
ここから先は、単発の指示（Prompt Engineering）ではなく、**継続的な文脈と記憶を設計する「Context Engineering（コンテキストエンジニアリング）」**の領域に入ります。
Andrej Karpathyが**「適切な情報を、適切なタイミングで供給する科学と芸術」**と定義したように、AIに「何をさせるか」の前に「何を知っている状態にするか」を設計することが主眼となります。

主な戦略は以下の4つです：
*   **Write（書き込み）**: 思考の下書きや長期記憶を持たせる。
*   **Select（選別）**: RAG等で、タスクに必要な情報だけを動的に選び出す。
*   **Compress（圧縮）**: 膨大なログを要約し、核心を残す。
*   **Isolate（隔離）**: 複雑なタスクを複数の専門エージェントに分割する。

---

## レベル4：専門（システム設計・コンテキスト管理）
**目的**：コンテキストエンジニアリングを駆使し、継続的に高品質なアウトプットを自動生成・運用する
**関係性**：System Admin / Daemon（管理者と常駐システム）

Karpathyが指摘するように、LLMはCPUであり、コンテキストウィンドウはRAMである。
Context Engineeringとは、**「OS（オペレーティングシステム）」として、限られたRAM（メモリ）に対して、必要なときに必要な情報だけをPaging（出し入れ）する技術**を指す。

*   **システム設計**: 単なるプロンプトではなく、RAG、API、Vector DBを組み合わせたパイプライン全体の設計。
*   **Context Optimization**:
    *   **Selection（選別）**: 必要な情報だけを動的にロードする。
    *   **Compression（圧縮）**: ログを要約し、核心を残す。
    *   **Isolation（隔離）**: 巨大なタスクを複数のエージェント（Sub-agents）に分割し、コンテキストを隔離して「Context Poisoning」を防ぐ。
*   **Human-in-the-Loop**: 自律動作するAIの成果物を人間がどう監査・修正するかのプロセス設計。

**習熟の目安**：AIが「人の補助」ではなく「業務プロセスの中核」として稼働し、自律的にタスクをこなす。

---

## レベル5：共創（環境と文脈の共同構築）
**目的**：AIと同じ環境（Context）に「住む」ことで、創造的タスクにおける生産性を飛躍的に高める
**関係性**：Partner / Partner（対等なエンジニアリングパートナー）

*   **環境共創（Ecosystem Co-creation）**
    *   AI自体に開発環境の操作権限を与え、双方向で環境を拡張する。
*   **動的コンテキスト共有（Live Context）**
    *   静的なプロンプトではなく、IDEのファイル、Git履歴、ログなどをリアルタイム共有。
*   **Passive Context Optimization (PCO)**
    *   `AI_CONTEXT.md` 等の定義ファイルを常駐させることで、都度指示せずとも「阿吽の呼吸」を実現する。

**習熟の目安**：AIに対して「命令」する感覚がなくなり、「相談」や「共同作業」の感覚になる。

---

## レベル6：真の対話（答え合わせと確信）
**目的**：共有されたコンテキストを基盤に、AIの純粋な「推論力」を使って、自身の仮説や直感の正しさを証明（あるいは棄却）する。
**関係性**：Thinker / Validator（思想家と検証者）

*   **帰納と演繹の合流（Convergence of Induction & Deduction）**
    *   **人間（帰納法）**: 泥臭い現場経験、最新の論文、直感から「事実」を集めて仮説を立てる。
    *   **AI（演繹法）**: 膨大な知識体系と論理を駆使して、純粋な思考実験から「理論値」を導き出す。
    *   この両者が一致した時、単なる「知識」は揺るぎない**「確信（Conviction）」**へと昇華される。
*   **Reasoning-Heavy Models（o1, o3等）の活用**
    *   検索（Web Search）を使わせず、あえてAIの脳内シミュレーションのみで回答させることで、論理の堅牢性をテストする。
    *   「配慮不要。推論の限界まで使え」という指示は、セーフティフィルタ（建前）を外し、純粋論理（本音）を引き出すためのトリガーとなる。
**科学的裏付け:** 2024年〜2025年のMITの研究「**The Platonic Representation Hypothesis**」により、**「高度なAIモデルは、異なるアーキテクチャや訓練データであっても、物理的実在に対して収束した内部表現（Converging Internal Representations）を持つ」**ことが示唆された。
つまり、Level 6における「答え合わせ」は、単なる偶然ではなく、AIと人間が異なるルートで登頂し、**「プラトン的真理」**という同じ山頂で出会う現象である。

**習熟の目安**：AIの回答に一喜一憂せず、「へえ、お前もそこまで登ってこれたんだ」と対等な目線で評価できる感覚（上から目線ではなく、同志としての目線）。

---

## 番外編：プロンプト哲学の分岐点
プロンプトのアプローチには、大きく分けて二つの流派が存在します。どちらが良い悪いではなく、目的に応じて使い分けることが重要です。

| アプローチ | 「型（Template）」の強制 | 「文脈（Context）」の共有 |
| :--- | :--- | :--- |
| **思想** | **「自由にさせない」** | **「自由にさせてるようでさせてない」** |
| **手法** | MECE、因果関係、出力フォーマットを厳密に定義する。 | 自分の哲学、判断基準、過去ログ（SSOT）を全て読ませる。 |
| **AIの役割** | **高性能な変換機** | **絶対的パートナー / 参謀** |
| **メリット** | 誰がやっても均質な「80点の正解」が出る。<br>コンテキスト不要（One-shot完結）。 | 形式はバラバラでも「自分にとっての120点の解」が出る。<br>阿吽の呼吸で会話できる。 |
| **デメリット** | 意外性（カオス）が死ぬ。<br>毎回指示を書くのが面倒。 | 初期セットアップ（Context構築）が重い。<br>AIがイエスマン化するリスクがある。 |

**「型」**は業務効率化やタスク処理、他者への展開（再現性）に向いており、
**「文脈」**は創造的パートナーシップや意思決定支援、自己探求に向いています。
高度なAIユーザーは、この二つを無意識に（あるいは定義ファイルを使って）ハイブリッドに運用しています。

---
*Created by Antigravity & User, 2025.*
