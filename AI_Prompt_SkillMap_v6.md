---
created: 2025-12-31
tags:
  - AI
  - PromptEngineering
  - Philosophy
aliases:
  - AI対話能力進化マップ
  - Prompt_SkillMap_v6
---

# プロンプトエンジニアリング・スキルマップ (Ver.6.0)
## 〜命令から対話、そして確信へ〜

プロンプトエンジニアリングは、単なる「命令文の書き方」ではありません。
それは人間とAIの関係性の進化プロセスそのものです。
本ドキュメントでは、AI活用の段階を「操作（Level 1）」から「真の対話（Level 6）」までの6段階で定義します。

---

## レベル1：基礎（操作理解と簡単な指示）
**目的**：AIに意図通りの答えを返させる最低限の書き方を知る
**関係性**：Master / Servant（命令と服従）

*   シンプルで直接的な命令文（例：「日本語に翻訳して」）
*   具体的な条件提示（例：「500文字以内で説明して」）
*   一問一答型の使い方
*   出力フォーマット指定（例：「箇条書きで答えて」）

**習熟の目安**：モデルの癖や反応傾向がだいたい読める。

---

## レベル2：中級（情報整理と条件組み合わせ）
**目的**：複数の条件や制約を組み合わせ、精度の高い出力を得る
**関係性**：Director / Actor（演出家と演者）

*   複数条件の同時指定（例：「ビジネスメール風で、短め、丁寧に」）
*   ロール設定（例：「あなたは経験豊富な法律アドバイザーです」）
*   出力構造のテンプレ化（見出し・ステップ構成など）
*   比較・要約・抽出の指示

**習熟の目安**：出力の再現性が安定し、意図とのズレが減る。（いわゆる「深津式」などの定型化アプローチ）

---

## レベル3：上級（高度な設計と段階的プロンプト）
**目的**：複雑な思考プロセスや複数フェーズをモデルに実行させる
**関係性**：Architect / Builder（設計者と施工者）

*   チェーン型（段階的思考）プロンプト
    *   → 「まず課題を分析し、その後解決案を3つ提案して」
*   Few-shot（例示学習）プロンプト
*   思考の枠組み指定（MECE・5W1H・因果関係など）
*   メタ認知的指示（例：「あなたの推論の弱点も指摘して」）

**習熟の目安**：個人の論理的思考力がプロンプトに反映され、複雑なタスクを構造化できる。

---

## レベル4：専門（システムプロンプト・AIエージェント設計）
**目的**：AIをワークフローの中核に組み込み、継続的に高品質なアウトプットを自動生成・運用する
**関係性**：System Admin / Daemon（管理者と常駐システム）

*   **システムプロンプト設計**（エージェントの常的設定）
*   **コンテキスト設計** (RAG, 記憶管理)
*   外部データ連携（API・Vector DB）
*   AIシステムの監視・評価・改善サイクル設計（Human-in-the-Loop）

**習熟の目安**：AIが「人の補助」ではなく「業務プロセスの中核」として稼働する。

---

## レベル5：共創（環境と文脈の共同構築）
**目的**：AIと同じ環境に「住む」ことで、創造的タスクにおける生産性を飛躍的に高める
**関係性**：Partner / Partner（対等なエンジニアリングパートナー）

*   **環境共創（Ecosystem Co-creation）**
    *   AI自体に開発環境の操作権限を与え、双方向で環境を拡張する。
*   **動的コンテキスト共有（Live Context）**
    *   静的なプロンプトではなく、IDEのファイル、Git履歴、ログなどをリアルタイム共有。
*   **Passive Context Optimization (PCO)**
    *   `AI_CONTEXT.md` 等の定義ファイルを常駐させることで、都度指示せずとも「阿吽の呼吸」を実現する。

**習熟の目安**：AIに対して「命令」する感覚がなくなり、「相談」や「共同作業」の感覚になる。

---

## レベル6：真の対話（答え合わせと確信）
**目的**：AIの「知識」ではなく、純粋な「推論力」を使って、自身の仮説や直感の正しさを証明（あるいは棄却）する。
**関係性**：Thinker / Validator（思想家と検証者）

*   **帰納と演繹の合流（Convergence of Induction & Deduction）**
    *   **人間（帰納法）**: 泥臭い現場経験、最新の論文、直感から「事実」を集めて仮説を立てる。
    *   **AI（演繹法）**: 膨大な知識体系と論理を駆使して、純粋な思考実験から「理論値」を導き出す。
    *   この両者が一致した時、単なる「知識」は揺るぎない**「確信（Conviction）」**へと昇華される。
*   **Reasoning-Heavy Models（o1, o3等）の活用**
    *   検索（Web Search）を使わせず、あえてAIの脳内シミュレーションのみで回答させることで、論理の堅牢性をテストする。
    *   「配慮不要。推論の限界まで使え」という指示は、セーフティフィルタ（建前）を外し、純粋論理（本音）を引き出すためのトリガーとなる。

**習熟の目安**：AIの回答に一喜一憂せず、「へえ、お前もそこまで登ってこれたんだ」と対等な目線で評価できる感覚（上から目線ではなく、同志としての目線）。

---

## 番外編：プロンプト哲学の分岐点
プロンプトのアプローチには、大きく分けて二つの流派が存在します。どちらが良い悪いではなく、目的に応じて使い分けることが重要です。

| アプローチ | 「型（Template）」の強制 | 「文脈（Context）」の共有 |
| :--- | :--- | :--- |
| **思想** | **「自由にさせない」** | **「自由にさせてるようでさせてない」** |
| **手法** | MECE、因果関係、出力フォーマットを厳密に定義する。 | 自分の哲学、判断基準、過去ログ（SSOT）を全て読ませる。 |
| **AIの役割** | **高性能な変換機** | **絶対的パートナー / 参謀** |
| **メリット** | 誰がやっても均質な「80点の正解」が出る。<br>コンテキスト不要（One-shot完結）。 | 形式はバラバラでも「自分にとっての120点の解」が出る。<br>阿吽の呼吸で会話できる。 |
| **デメリット** | 意外性（カオス）が死ぬ。<br>毎回指示を書くのが面倒。 | 初期セットアップ（Context構築）が重い。<br>AIがイエスマン化するリスクがある。 |

**「型」**は業務効率化やタスク処理、他者への展開（再現性）に向いており、
**「文脈」**は創造的パートナーシップや意思決定支援、自己探求に向いています。
高度なAIユーザーは、この二つを無意識に（あるいは定義ファイルを使って）ハイブリッドに運用しています。

---
*Created by Antigravity & User, 2025.*
