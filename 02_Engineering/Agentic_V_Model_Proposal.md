# Agentic V-Model: AI時代における「設計とテスト」の再考（作業仮説）

## まえがき：なぜ今、「V字モデル」なのか？
AIによるコード生成速度が極限まで高まった現在、人間の役割は「コーディング」から「設計と検証」へとシフトしているのではないか。
IBMやMicrosoftなどの先行研究においても、「要件定義からテストまでAIエージェントを活用する」という議論は始まっているが、**「AIにどのように設計させるか（How）」** という具体的なメソドロジーについては、まだ多くの議論の余地がある。

本稿では、伝統的なシステム開発手法である「V字モデル（V-Model）」をAIエージェント開発に適用し、MITの「Concepts & Synchronizations」理論と組み合わせることで、**「自律的かつ堅牢な開発プロセス（Agentic Workflow）」** を構築できるのではないか、という一つの作業仮説を提示する。

これは単なる過去への回帰ではない。**先人たちが築いた知見を、AIという新しいパートナーと共に再実装する試み** である。

---

## 1. 従来のAI開発の課題：Vibe Codingのジレンマ
現在のAI開発（特にチャットベースの開発）は、その速度と引き換えに、いくつかの課題を抱えているように見える。

*   **プロセスの短絡**: 「要件（Idea）」からいきなり「実装（Coding）」へジャンプしがちである。
*   **検証の難しさ**: 「動いたからOK」という感覚的な判断に依存しやすく、網羅的なテストが後回しになる。
*   **技術的負債**: 構造化されていないため、AIのコンテキスト長を超えた瞬間に破綻するリスクがある。

AIは「指示通りに書く」能力は高いが、「全体像（Architecture）」を維持する能力は人間に依存している。人間が構造を示さなければ、AIはその高い能力を活かしきれない可能性がある。

## 2. Agentic V-Modelの提案
我々は、AI開発プロセスを以下の**V字型**に再構築することで、これらの課題を解決できるのではないかと考えている。

| 左側：設計プロセス (Downstream) | 右側：検証プロセス (Upstream) | 担当エージェント |
| :--- | :--- | :--- |
| **1. 要件定義 (Requirement)**<br>ユーザーのアイデア、ゴール設定 | **4. 受入テスト (Acceptance)**<br>ユーザー自身による動作確認 | **Human (User)** |
| **2. 基本設計 (Concepts)**<br>独立した機能単位の定義 (MIT C&S) | **3. システムテスト (System)**<br>Concepts間の整合性チェック | **Manager AI** |
| **3. 詳細設計 (Sync / Protocol)**<br>機能間の通信仕様定義 | **2. 結合テスト (Integration)**<br>Protocol通りの通信確認 | **Manager AI** |
| **4. 実装 (Implementation)**<br>具体的なコード記述 | **1. 単体テスト (Unit)**<br>Concept単体の動作確認 | **Worker AI** |

### コアとなる技術：MIT C&S (Concepts & Synchronizations)
このモデルの核として提案したいのが、MITが提唱するソフトウェア設計理論「Concepts」である。
*   **Concept**: 独立した機能の塊（例：User, Todo, Auth）。
*   **Sync**: Concept間の同期（通信プロトコル）。

これを設計フェーズで明確に定義することで、AIマネージャーは**「設計図通りに実装されているか？」という客観的なテスト基準**を持つことができる。
既存のAgentic AI議論では「AIに役割を与える」ことに主眼が置かれているが、本モデルは**「AIに判断基準（Criteria）を与える」**点において、新しい視点を提供できるかもしれない。

---

## 3. 実践：管理職AIの役割（理論的実装）
Agentic V-Modelにおいて、最も重要な役割を担うのが**「中間管理職（Manager AI）」**であると想定される。
彼らはコードを書くのではなく、**「設計と実装の整合性（Quality Assurance）」** を担保する役割を果たす。

### Manager AIの仕事
1.  **設計リント (Architectural Linting)**:
    *   Humanから渡された要件をMIT C&Sに基づいて分解する。
    *   「このConceptは独立していません」「依存関係が循環しています」と指摘する。
2.  **結合テストの自動生成**:
    *   定義されたSync（プロトコル）に基づいて、結合テストケースを自動生成する。
    *   Web APIならOpenAPI仕様書、関数ならInterface定義書を出力する。
3.  **部下AIへの指示と却下**:
    *   Worker AIが書いたコードをチェックし、**「単体テストは通ってるけど、Sync仕様と違うからリジェクト」** という判断を下す。

### 3.1. 専門家AIチームによる品質保証 (The Specialized Squad)
「人間がボトルネックになる」という課題は、人間が全ての工程をチェックしようとするから発生するのではないか。
Agentic V-Modelの右側（検証フェーズ）では、以下の専門家エージェントを配置することで、人間は「コードレビュー」から解放され、「受入テスト（UAT）」のみに集中できる体制を目指す。

| 役割 (Role) | 担当フェーズ | 任務 (Mission) | 狙い (Why?) |
| :--- | :--- | :--- | :--- |
| **Security Agent (SCA)** | 静的解析 / 脆弱性診断 | コードの脆弱性（SQL Injection, XSS等）や依存ライブラリのリスクを自動スキャンする。 | 人間が見落としがちな既知の脆弱性を機械的に排除する。 |
| **Chaos Agent (CEA)** | 異常系テスト / 負荷試験 | 「DBが落ちたら？」「通信が切れたら？」「不正な入力が来たら？」といった意地悪なテストケースを自動生成し、システムを攻撃する。 | 「正常系しかテストしない」というAIの楽観バイアスをカバーする。 |
| **Traceability Agent (TRA)** | 要件追跡 / ドキュメント整合 | 「要件（MIT C&S）」⇔「実装コード」⇔「テスト結果」の紐付きを記録し、改修時の影響範囲を可視化する。 | 「動いてるけど、どの要件に対応してるか不明」というブラックボックス化を防ぐ。 |

人間（Human）の役割は、これらのエージェントが提出する**「3つの合格レポート（All Green Reports）」**を確認し、最終的な**受入テスト（UAT: User Acceptance Test）**を行うことだけに集約されるべきである。
これにより、人間は「高速なAIの処理速度」に張り合う必要がなくなり、「最終責任者（Approver）」としての地位を維持できるのではないか。

## 4. 展望：AIを「部下」にするための共通言語として
AIに「いい感じに作って」と指示するのは、アルバイトに経営判断を任せるようなリスクを伴う。
指揮官（Human）が為すべきことは、**「構造（Structure）」と「基準（Criteria）」** を明確にすることではないだろうか。

MIT C&Sを用いたAgentic V-Modelは、曖昧な自然言語指示を、**「テスト可能な仕様（Testable Spec）」** に変換する一つの解法（Language）として機能する可能性がある。
本稿はあくまで理論的な作業仮説（Working Hypothesis）に過ぎないが、このフレームワークが実装されれば、人間はマイクロマネジメントから解放され、真の意味でAIを「パートナー（Agent）」として迎え入れることができるようになるだろう。

**設計せよ。実装はAIに委ねよ。**
**検証せよ。品質は構造に宿る。**

---
*Note: 本稿は個人的な思考実験に基づく作業仮説であり、特定の組織や団体を代表するものではありません。実証実験および議論の深化を期待します。*
